# backend/services/whisper_service.py
import os
import tempfile
from faster_whisper import WhisperModel

whisper_model = None

def initialize_whisper_model():
    global whisper_model
    if whisper_model is None:
        print("ğŸš€ åˆå§‹åŒ– Whisper æ¨¡å‹ï¼ˆtinyï¼‰...")
        whisper_model = WhisperModel("tiny", compute_type="int8", device="cpu")
        print("âœ… Whisper æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼")
    return whisper_model


def transcribe_audio(file):
    # ç¢ºä¿æ¨¡å‹å·²åˆå§‹åŒ–
    model = initialize_whisper_model() # é€™è£¡ç¾åœ¨æœƒå–å¾—åˆå§‹åŒ–éå¾Œçš„æ¨¡å‹

    # åˆ¤æ–·æ˜¯å¦ç‚º UploadFileï¼ˆFastAPI å‚³é€ï¼‰ï¼Œé‚„æ˜¯ bytesï¼ˆStreamlit å‚³é€ï¼‰
    if hasattr(file, "file"):
        audio_bytes = file.file.read()
    else:
        audio_bytes = file

    # å°‡éŸ³è¨Šå¯«å…¥æš«å­˜æª”
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
        tmp.write(audio_bytes)
        tmp_path = tmp.name

    try:
        segments, _ = model.transcribe(tmp_path, beam_size=5) # ä½¿ç”¨å–å¾—çš„æ¨¡å‹å¯¦ä¾‹
        text = " ".join([seg.text for seg in segments])
        return text.strip()
    finally:
        os.remove(tmp_path)
